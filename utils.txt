import functools
import heapq
import copy
from collections import deque
from queue import PriorityQueue


class RoverPosition:
    def __init__(self, x, y, orientation):
        self.X = x
        self.Y = y
        self.orientation = orientation

    def get_location(self):
        return self.X, self.Y

    def set_location(self, x, y):
        self.X = x
        self.Y = y

    def get_orientation(self):
        return self.orientation

    def set_orientation(self, orientation):
        self.orientation = orientation

    def __eq__(self, other):
        if (other.get_location() == self.get_location() and
                other.get_orientation() == self.get_orientation()):
            return True
        else:
            return False
    
    def __hash__(self):
        # We use the hash value of the state
        # stored in the node instead of the node
        # object itself to quickly search a node
        # with the same state in a Hash Table
        return hash(self.X)*hash(self.Y)*hash(self.orientation)

class PriorityQueue:
    """A Queue in which the minimum (or maximum) element (as determined by f and
    order) is returned first.
    If order is 'min', the item with minimum f(x) is
    returned first; if order is 'max', then it is the item with maximum f(x).
    Also supports dict-like lookup."""

    def __init__(self, order='min', f=lambda x: x):
        self.heap = []
        if order == 'min':
            self.f = f
        elif order == 'max':  # now item with max f(x)
            self.f = lambda x: -f(x)  # will be popped first
        else:
            raise ValueError("Order must be either 'min' or 'max'.")

    def append(self, item):
        """Insert item at its correct position."""
        heapq.heappush(self.heap, (self.f(item), item))

    def extend(self, items):
        """Insert each item in items at its correct position."""
        for item in items:
            self.append(item)

    def pop(self):
        """Pop and return the item (with min or max f(x) value)
        depending on the order."""
        if self.heap:
            return heapq.heappop(self.heap)[1]
        else:
            raise Exception('Trying to pop from empty PriorityQueue.')

    def __len__(self):
        """Return current capacity of PriorityQueue."""
        return len(self.heap)

    def __contains__(self, key):
        """Return True if the key is in PriorityQueue."""
        return any([item == key for _, item in self.heap])

    def __getitem__(self, key):
        """Returns the first value associated with key in PriorityQueue.
        Raises KeyError if key is not present."""
        for value, item in self.heap:
            if item == key:
                return value
        raise KeyError(str(key) + " is not in the priority queue")

    def __delitem__(self, key):
        """Delete the first occurrence of key."""
        try:
            del self.heap[[item == key for _, item in self.heap].index(True)]
        except ValueError:
            raise KeyError(str(key) + " is not in the priority queue")
        heapq.heapify(self.heap)


class Node:
    """A node in a search tree. Contains a pointer to the parent (the node
    that this is a successor of) and to the actual state for this node. Note
    that if a state is arrived at by two paths, then there are two nodes with
    the same state. Also includes the action that got us to this state, and
    the total path_cost (also known as g) to reach the node. Other functions
    may add an f and h value; see best_first_graph_search and astar_search for
    an explanation of how the f and h values are handled. You will not need to
    subclass this class."""

    def __init__(self, state, parent=None, action=None, path_cost=0):
        """Create a search tree Node, derived from a parent by an action."""
        self.state = state
        self.parent = parent
        self.action = action
        self.path_cost = path_cost
        self.depth = 0
        if parent:
            self.depth = parent.depth + 1

    def __repr__(self):
        return "<Node {}>".format(self.state)

    def __lt__(self, node):
        return self.path_cost < node.path_cost

    def expand(self, problem):
        """List the nodes reachable in one step from this node."""
        return [self.child_node(problem, action)
                for action in problem.actions(self.state)]

    def child_node(self, problem, action):
        """[Figure 3.10]"""
        x, y = self.state.get_location()
        orientation = self.state.get_orientation()
        rover_pos = RoverPosition(x,y,orientation)
        next_state = problem.result(rover_pos, action)
        next_node = Node(next_state, self, action, problem.path_cost(self.path_cost, self.state, action, next_state))
        return next_node

    def solution(self):
        """Return the sequence of actions to go from the root to this node."""
        return [node.action for node in self.path()[1:]]

    def path(self):
        """Return a list of nodes forming the path from the root to this node."""
        node, path_back = self, []
        while node:
            path_back.append(node)
            node = node.parent
        return list(reversed(path_back))

    # We want for a queue of nodes in breadth_first_graph_search or
    # astar_search to have no duplicated states, so we treat nodes
    # with the same state as equal. [Problem: this may not be what you
    # want in other contexts.]

    def __eq__(self, other):
        return isinstance(other, Node) and self.state == other.state and self.action == other.action

    def __hash__(self):
        # We use the hash value of the state
        # stored in the node instead of the node
        # object itself to quickly search a node
        # with the same state in a Hash Table
        return hash(self.state)*hash(self.action)

class Problem:
    """The abstract class for a formal problem. You should subclass
    this and implement the methods actions and result, and possibly
    __init__, goal_test, and path_cost. Then you will create instances
    of your subclass and solve them with the various search functions."""

    def __init__(self, initial, goal=None):
        """The constructor specifies the initial state, and possibly a goal
        state, if there is a unique goal. Your subclass's constructor can add
        other arguments."""
        self.initial = initial
        self.goal = goal

    def actions(self, state):
        """Return the actions that can be executed in the given
        state. The result would typically be a list, but if there are
        many actions, consider yielding them one at a time in an
        iterator, rather than building them all at once."""
        raise NotImplementedError

    def result(self, state, action):
        """Return the state that results from executing the given
        action in the given state. The action must be one of
        self.actions(state)."""
        raise NotImplementedError

    def goal_test(self, state):
        """Return True if the state is a goal. The default method compares the
        state to self.goal or checks for state in self.goal if it is a
        list, as specified in the constructor. Override this method if
        checking against a single self.goal is not enough."""
        if isinstance(self.goal, list):
            return is_in(state, self.goal)
        else:
            return state == self.goal

    def path_cost(self, c, state1, action, state2):
        """Return the cost of a solution path that arrives at state2 from
        state1 via action, assuming cost c to get up to state1. If the problem
        is such that the path doesn't matter, this function will only look at
        state2. If the path does matter, it will consider c and maybe state1
        and action. The default method costs 1 for every step in the path."""
        return c + 1

    def value(self, state):
        """For optimization problems, each state has a value. Hill Climbing
        and related algorithms try to maximize this value."""
        raise NotImplementedError
    
class PlanRoute(Problem):
    """ The problem of moving the Hybrid Wumpus Agent from one place to other """

    def __init__(self, initial, goal, allowed, dimrow):
        """ Define goal state and initialize a problem """
        super().__init__(initial, goal)
        self.dimrow = dimrow
        self.goal = goal
        self.allowed = allowed

    def actions(self, state):
        """ Return the actions that can be executed in the given state.
        The result would be a list, since there are only three possible actions
        in any given state of the environment """

        possible_actions = ['Forward', 'Turnleft', 'Turnright']
        x, y = state.get_location()
        orientation = state.get_orientation()

        # Prevent Bumps
        if x == 0 and orientation == 'left':
            if 'Forward' in possible_actions:
                possible_actions.remove('Forward')
        if y == 0 and orientation == 'up':
            if 'Forward' in possible_actions:
                possible_actions.remove('Forward')
        if x == self.dimrow-1 and orientation == 'right':
            if 'Forward' in possible_actions:
                possible_actions.remove('Forward')
        if y == self.dimrow-1 and orientation == 'down':
            if 'Forward' in possible_actions:
                possible_actions.remove('Forward')
        return possible_actions

    def result(self, state, action):
        """ Given state and action, return a new state that is the result of the action.
        Action is assumed to be a valid action in the state """
        x, y = state.get_location()
        proposed_loc = list()

        # Move Forward
        if action == 'Forward':
            if state.get_orientation() == 'up':
                proposed_loc = [x, y - 1]
            elif state.get_orientation() == 'down':
                proposed_loc = [x, y + 1]
            elif state.get_orientation() == 'left':
                proposed_loc = [x - 1, y]
            elif state.get_orientation() == 'right':
                proposed_loc = [x + 1, y]
            else:
                raise Exception('InvalidOrientation')

        # Rotate counter-clockwise
        elif action == 'Turnleft':
            if state.get_orientation() == 'up':
                state.set_orientation('left')
            elif state.get_orientation() == 'down':
                state.set_orientation('right')
            elif state.get_orientation() == 'left':
                state.set_orientation('down')
            elif state.get_orientation() == 'right':
                state.set_orientation('up')
            else:
                raise Exception('InvalidOrientation')

        # Rotate clockwise
        elif action == 'Turnright':
            if state.get_orientation() == 'up':
                state.set_orientation('right')
            elif state.get_orientation() == 'down':
                state.set_orientation('left')
            elif state.get_orientation() == 'left':
                state.set_orientation('up')
            elif state.get_orientation() == 'right':
                state.set_orientation('down')
            else:
                raise Exception('InvalidOrientation')
        if proposed_loc in self.allowed:
            state.set_location(proposed_loc[0], proposed_loc[1])
        return state

    def goal_test(self, state):
        """ Given a state, return True if state is a goal state or False, otherwise """

        return state.get_location() == tuple(self.goal)

    def h(self, node):
        """ Return the heuristic value for a given state."""

        # Manhattan Heuristic Function
        x1, y1 = node.state.get_location()
        x2, y2 = self.goal

        return abs(x2 - x1) + abs(y2 - y1)
    
class PlanRouteSandy(Problem):
    """ The problem of moving the Hybrid Wumpus Agent from one place to other """

    def __init__(self, initial, goal, allowed, sandy, dimrow):
        """ Define goal state and initialize a problem """
        super().__init__(initial, goal)
        self.dimrow = dimrow
        self.goal = goal
        self.allowed = allowed
        self.sandy = sandy

    def actions(self, state):
        """ Return the actions that can be executed in the given state.
        The result would be a list, since there are only three possible actions
        in any given state of the environment """

        possible_actions = ['Forward', 'Turnleft', 'Turnright']
        x, y = state.get_location()
        orientation = state.get_orientation()

        # Prevent Bumps
        if x == 0 and orientation == 'left':
            if 'Forward' in possible_actions:
                possible_actions.remove('Forward')
        if y == 0 and orientation == 'up':
            if 'Forward' in possible_actions:
                possible_actions.remove('Forward')
        if x == self.dimrow-1 and orientation == 'right':
            if 'Forward' in possible_actions:
                possible_actions.remove('Forward')
        if y == self.dimrow-1 and orientation == 'down':
            if 'Forward' in possible_actions:
                possible_actions.remove('Forward')
        return possible_actions

    def result(self, state, action):
        """ Given state and action, return a new state that is the result of the action.
        Action is assumed to be a valid action in the state """
        x, y = state.get_location()
        proposed_loc = list()

        # Move Forward
        if action == 'Forward':
            if state.get_orientation() == 'up':
                proposed_loc = [x, y - 1]
            elif state.get_orientation() == 'down':
                proposed_loc = [x, y + 1]
            elif state.get_orientation() == 'left':
                proposed_loc = [x - 1, y]
            elif state.get_orientation() == 'right':
                proposed_loc = [x + 1, y]
            else:
                raise Exception('InvalidOrientation')

        # Rotate counter-clockwise
        elif action == 'Turnleft':
            if state.get_orientation() == 'up':
                state.set_orientation('left')
            elif state.get_orientation() == 'down':
                state.set_orientation('right')
            elif state.get_orientation() == 'left':
                state.set_orientation('down')
            elif state.get_orientation() == 'right':
                state.set_orientation('up')
            else:
                raise Exception('InvalidOrientation')

        # Rotate clockwise
        elif action == 'Turnright':
            if state.get_orientation() == 'up':
                state.set_orientation('right')
            elif state.get_orientation() == 'down':
                state.set_orientation('left')
            elif state.get_orientation() == 'left':
                state.set_orientation('up')
            elif state.get_orientation() == 'right':
                state.set_orientation('down')
            else:
                raise Exception('InvalidOrientation')
        if proposed_loc in self.allowed:
            state.set_location(proposed_loc[0], proposed_loc[1])
        return state

    def goal_test(self, state):
        """ Given a state, return True if state is a goal state or False, otherwise """

        return state.get_location() == tuple(self.goal)
    
    def path_cost(self, c, state1, action, state2):
        """Return the cost of a solution path that arrives at state2 from
        state1 via action, assuming cost c to get up to state1. If the problem
        is such that the path doesn't matter, this function will only look at
        state2. If the path does matter, it will consider c and maybe state1
        and action. The default method costs 1 for every step in the path. This
        method incorperates sandy squares and moving through them having c = 2"""

        if action == "forward" or action == "rotate_cw" or action == "rotate_ccw" and self.cell in sandy_cells:
            return c + 2
        else:
            return c + 1
        #return c + 1
    
    def h(self, node):
        """ Return the heuristic value for a given state."""

        # Manhattan Heuristic Function
        x1, y1 = node.state.get_location()
        x2, y2 = self.goal

        return abs(x2 - x1) + abs(y2 - y1)
    
#def astar_search(problem, heuristic):
#    def reconstruct_path(node):
#        path = []
#        while node is not None:
#            path.append(node.action)
#            node = node.parent
#        return list(reversed(path))
#
#    start_node = Node(problem.initial)
#    if problem.goal_test(start_node.state):
#        return reconstruct_path(start_node)
#
#    frontier = PriorityQueue()
#    frontier.put(start_node)
#    explored = set()
#
#    while not frontier.empty():
#        node = frontier.get()
#        explored.add(node.state)
#
#        for action in problem.actions(node.state):
#            child_state = problem.result(node.state, action)
#            if child_state not in explored:
#                child_node = Node(child_state, node, action, node.path_cost + problem.step_cost(node.state, action))
#                if problem.goal_test(child_node.state):
#                    return reconstruct_path(child_node)
#                frontier.put(child_node)
#
#    return None
#
#result_path = astar_search(problem, heuristic=)


    
def breadth_first_graph_search(problem):
    """[Figure 3.11]
    Note that this function can be implemented in a
    single line as below:
    return graph_search(problem, FIFOQueue())
    """
    node = Node(problem.initial)
    if problem.goal_test(node.state):
        return node
    frontier = deque([node])
    explored = set()
    while frontier:
        node = frontier.popleft()
        explored.add(node.state)
        for child in node.expand(problem):
            if child.state not in explored and child not in frontier:
                if problem.goal_test(child.state):
                    return child
                frontier.append(child)
    return None

def frontier_contains_state(frontier, state):
    for _, n in frontier.queue:
        if n.state == state:
            return True
    return False


def is_in(elt, seq):
    """Similar to (elt in seq), but compares with 'is', not '=='."""
    return any(x is elt for x in seq)